{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboostNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading catboost-0.24.1-cp38-none-win_amd64.whl (65.3 MB)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.14.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: six in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from catboost) (1.5.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from catboost) (1.0.5)\n",
      "Collecting plotly\n",
      "  Downloading plotly-4.10.0-py2.py3-none-any.whl (13.0 MB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from catboost) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from catboost) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ualkhanova_a\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1108)'))': /simple/catboost/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11435 sha256=e1d303b107afe7feaecb067c0156cb414dc9fa76a6546c3f57623ed42f420cee\n",
      "  Stored in directory: c:\\users\\ualkhanova_a\\appdata\\local\\pip\\cache\\wheels\\c4\\a7\\48\\0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
      "Successfully built retrying\n",
      "Installing collected packages: graphviz, retrying, plotly, catboost\n",
      "Successfully installed catboost-0.24.1 graphviz-0.14.1 plotly-4.10.0 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_auto_ru_09_09_2020.csv', 'all_auto_ru_24_08_2020.csv', 'all_car_brands_and_their_models_from_auto_ru.csv', 'auto_ru.csv', 'df3.csv', 'df3_cols.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor, DecisionTreeRegressor\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import os\n",
    "print(os.listdir('./data'))\n",
    "PATH_to_file = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_module09092020 as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.33 # 33%\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тренировочного датасета:  (52085, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyType</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>vehicleTransmission</th>\n",
       "      <th>Привод</th>\n",
       "      <th>ПТС</th>\n",
       "      <th>model2</th>\n",
       "      <th>mileage</th>\n",
       "      <th>modelDate</th>\n",
       "      <th>productionDate</th>\n",
       "      <th>enginePower</th>\n",
       "      <th>engineDisplacement2</th>\n",
       "      <th>engineDisplacement2_log</th>\n",
       "      <th>numberOfDoors</th>\n",
       "      <th>Владельцы</th>\n",
       "      <th>count_words_d</th>\n",
       "      <th>mean_c_w</th>\n",
       "      <th>sum_c_w</th>\n",
       "      <th>dif_b_prod_model</th>\n",
       "      <th>Train</th>\n",
       "      <th>id</th>\n",
       "      <th>c_p_des1</th>\n",
       "      <th>m_s_w_des2</th>\n",
       "      <th>r_l_s_des3</th>\n",
       "      <th>abs_des4</th>\n",
       "      <th>c_c_des5</th>\n",
       "      <th>a_w_des6</th>\n",
       "      <th>r_v_c_des7</th>\n",
       "      <th>price_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>седан</td>\n",
       "      <td>AUDI</td>\n",
       "      <td>чёрный</td>\n",
       "      <td>бензин</td>\n",
       "      <td>MECHANICAL</td>\n",
       "      <td>полный</td>\n",
       "      <td>Оригинал</td>\n",
       "      <td>2.8</td>\n",
       "      <td>350000</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>174</td>\n",
       "      <td>2800</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.206073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>седан</td>\n",
       "      <td>AUDI</td>\n",
       "      <td>красный</td>\n",
       "      <td>бензин</td>\n",
       "      <td>MECHANICAL</td>\n",
       "      <td>передний</td>\n",
       "      <td>Оригинал</td>\n",
       "      <td>1.8</td>\n",
       "      <td>173424</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>90</td>\n",
       "      <td>1800</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>18</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.002100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bodyType brand    color fuelType vehicleTransmission    Привод       ПТС  \\\n",
       "0    седан  AUDI   чёрный   бензин          MECHANICAL    полный  Оригинал   \n",
       "1    седан  AUDI  красный   бензин          MECHANICAL  передний  Оригинал   \n",
       "\n",
       "  model2  mileage  modelDate  productionDate  enginePower  \\\n",
       "0    2.8   350000         30              29          174   \n",
       "1    1.8   173424         38              34           90   \n",
       "\n",
       "   engineDisplacement2  engineDisplacement2_log  numberOfDoors  Владельцы  \\\n",
       "0                 2800                        7              4          3   \n",
       "1                 1800                        7              4          3   \n",
       "\n",
       "   count_words_d  mean_c_w  sum_c_w  dif_b_prod_model  Train  id  c_p_des1  \\\n",
       "0             32  0.000331       30                -1      1 NaN         0   \n",
       "1             21  0.000199       18                -4      1 NaN         0   \n",
       "\n",
       "   m_s_w_des2  r_l_s_des3  abs_des4  c_c_des5  a_w_des6  r_v_c_des7  price_log  \n",
       "0           0           0         0         0         0           0  12.206073  \n",
       "1           0           0         0         0         0           0  11.002100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тестового датасета:  (3837, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyType</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>modelDate</th>\n",
       "      <th>name</th>\n",
       "      <th>numberOfDoors</th>\n",
       "      <th>productionDate</th>\n",
       "      <th>vehicleConfiguration</th>\n",
       "      <th>vehicleTransmission</th>\n",
       "      <th>engineDisplacement</th>\n",
       "      <th>enginePower</th>\n",
       "      <th>description</th>\n",
       "      <th>mileage</th>\n",
       "      <th>Комплектация</th>\n",
       "      <th>Привод</th>\n",
       "      <th>Руль</th>\n",
       "      <th>Состояние</th>\n",
       "      <th>Владельцы</th>\n",
       "      <th>ПТС</th>\n",
       "      <th>Таможня</th>\n",
       "      <th>Владение</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>седан</td>\n",
       "      <td>BMW</td>\n",
       "      <td>чёрный</td>\n",
       "      <td>дизель</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>520d 2.0d AT (190 л.с.)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>SEDAN AUTOMATIC 2.0</td>\n",
       "      <td>автоматическая</td>\n",
       "      <td>2.0 LTR</td>\n",
       "      <td>190 N12</td>\n",
       "      <td>В РОЛЬФ Ясенево представлено более 500 автомоб...</td>\n",
       "      <td>158836.0</td>\n",
       "      <td>['[{\"name\":\"Безопасность\",\"values\":[\"Антипробу...</td>\n",
       "      <td>задний</td>\n",
       "      <td>Левый</td>\n",
       "      <td>Не требует ремонта</td>\n",
       "      <td>1 владелец</td>\n",
       "      <td>Оригинал</td>\n",
       "      <td>Растаможен</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>седан</td>\n",
       "      <td>BMW</td>\n",
       "      <td>белый</td>\n",
       "      <td>дизель</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>318d 2.0d AT (150 л.с.)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>SEDAN AUTOMATIC 2.0</td>\n",
       "      <td>автоматическая</td>\n",
       "      <td>2.0 LTR</td>\n",
       "      <td>150 N12</td>\n",
       "      <td>Автомобиль из демонстрационного парка по спец ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['[{\"name\":\"Комфорт\",\"values\":[\"Круиз-контроль...</td>\n",
       "      <td>задний</td>\n",
       "      <td>Левый</td>\n",
       "      <td>Не требует ремонта</td>\n",
       "      <td>1 владелец</td>\n",
       "      <td>Оригинал</td>\n",
       "      <td>Растаможен</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bodyType brand   color fuelType  modelDate                     name  \\\n",
       "0    седан   BMW  чёрный   дизель     2016.0  520d 2.0d AT (190 л.с.)   \n",
       "1    седан   BMW   белый   дизель     2018.0  318d 2.0d AT (150 л.с.)   \n",
       "\n",
       "   numberOfDoors  productionDate vehicleConfiguration vehicleTransmission  \\\n",
       "0            4.0          2017.0  SEDAN AUTOMATIC 2.0      автоматическая   \n",
       "1            4.0          2019.0  SEDAN AUTOMATIC 2.0      автоматическая   \n",
       "\n",
       "  engineDisplacement enginePower  \\\n",
       "0            2.0 LTR     190 N12   \n",
       "1            2.0 LTR     150 N12   \n",
       "\n",
       "                                         description   mileage  \\\n",
       "0  В РОЛЬФ Ясенево представлено более 500 автомоб...  158836.0   \n",
       "1  Автомобиль из демонстрационного парка по спец ...      10.0   \n",
       "\n",
       "                                        Комплектация  Привод   Руль  \\\n",
       "0  ['[{\"name\":\"Безопасность\",\"values\":[\"Антипробу...  задний  Левый   \n",
       "1  ['[{\"name\":\"Комфорт\",\"values\":[\"Круиз-контроль...  задний  Левый   \n",
       "\n",
       "            Состояние   Владельцы       ПТС     Таможня Владение  id  \n",
       "0  Не требует ремонта  1 владелец  Оригинал  Растаможен      NaN   0  \n",
       "1  Не требует ремонта  1 владелец  Оригинал  Растаможен      NaN   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность датасета c примером сабмишена:  (3837, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5299000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1580000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      price\n",
       "0   0  5299000.0\n",
       "1   1  1580000.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# это блок закомментирован и требуется для закачивания готового датасета\n",
    "\n",
    "df3 = pd.read_csv(PATH_to_file+'df3.csv')\n",
    "df_test = pd.read_csv(PATH_to_file+'test.csv')\n",
    "df_submit = pd.read_csv(PATH_to_file+'sample_submission.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Размерность тренировочного датасета: ', df3.shape)\n",
    "display(df3.head(2))\n",
    "print('Размерность тестового датасета: ', df_test.shape)\n",
    "display(df_test.head(2))\n",
    "print('Размерность датасета c примером сабмишена: ', df_submit.shape)\n",
    "display(df_submit.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем думми переменные из категориальных переменных\n",
    "df3 = pd.get_dummies(df3, columns = ['bodyType', 'brand', 'color', 'fuelType', 'vehicleTransmission', 'Привод', 'Владельцы', 'ПТС', 'model2', 'engineDisplacement2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df3.query('Train==1').drop(['Train'], axis = 1)\n",
    "test = df3.query('Train==0').drop(['Train'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['price_log', 'id'], axis=1).reset_index(drop=True)\n",
    "y_train = train['price_log'].values\n",
    "X_test = test.drop(['price_log', 'id'], axis=1).reset_index(drop=True)\n",
    "y_test = test['price_log'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.006\n",
      " Test MAPE: 0.552\n"
     ]
    }
   ],
   "source": [
    "# Проверим RandomForestRegressor\n",
    "rf  = RandomForestRegressor(random_state=RANDOM_SEED) \n",
    "rf.fit(X, y)\n",
    "y_train_predict = rf.predict(X)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 177.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 353.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#попробуем поискать лучшие значения для случайного леса\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=RANDOM_SEED, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1200,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 110,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.006\n",
      " Test MAPE: 0.464\n"
     ]
    }
   ],
   "source": [
    "# Проверим RandomForestRegressor с лучшими параметрами\n",
    "rf  = RandomForestRegressor(random_state=RANDOM_SEED, n_estimators = 1200, min_samples_split = 2, min_samples_leaf = 1, \n",
    "                            max_features = 'sqrt', max_depth = 110, bootstrap = True) \n",
    "rf.fit(X_train, y_train)\n",
    "y_train_predict = rf.predict(X_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#что то результат не очень 46,4% получим Submission  \n",
    "Sub = np.exp(y_predict)\n",
    "submit = pd.DataFrame(test.id)\n",
    "submit['default']=Sub\n",
    "submit.to_csv('submission_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.000\n",
      " Test MAPE: 0.590\n"
     ]
    }
   ],
   "source": [
    "# Проверим DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_train_predict = dtr.predict(X_train)\n",
    "y_predict = dtr.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.072\n",
      " Test MAPE: 545100.493\n"
     ]
    }
   ],
   "source": [
    "# Проверим LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_predict = lr.predict(X_train)\n",
    "y_predict = lr.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 870.438\n",
      " Test MAPE: 38963127.032\n"
     ]
    }
   ],
   "source": [
    "# проверим BaggingClassifier - делит выборку на бутстрап выборки а потом из нескольких моделей создает усредненный результат\n",
    "BagClas_lr = BaggingRegressor(lr, n_estimators=3, n_jobs=-1, random_state=RANDOM_SEED)\n",
    "BagClas_lr.fit(X_train, y_train)\n",
    "y_train_predict = BagClas_lr.predict(X_train)\n",
    "y_predict = BagClas_lr.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.046\n",
      " Test MAPE: 0.553\n"
     ]
    }
   ],
   "source": [
    "# проверим градиентный бустинг\n",
    "gbr = GradientBoostingRegressor(n_estimators=300)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_train_predict = gbr.predict(X_train)\n",
    "y_predict = gbr.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(random_state = RANDOM_SEED)\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'learning_rate':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "             'n_estimators':[100, 250, 500, 750, 1000, 1250, 1500, 1750]}\n",
    "\n",
    "rf_random = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(rf_random.best_params_)\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.012\n",
      " Test MAPE: 0.048\n"
     ]
    }
   ],
   "source": [
    "rf = GradientBoostingRegressor(random_state = RANDOM_SEED, learning_rate = 0.1, n_estimators = 750)\n",
    "rf.fit(X_train, y_train)\n",
    "y_train_predict = rf.predict(X_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.000\n",
      " Test MAPE: 0.081\n"
     ]
    }
   ],
   "source": [
    "# проверить ExtraTreeRegressor\n",
    "etr = ExtraTreeRegressor(random_state = RANDOM_SEED)\n",
    "etr.fit(X_train, y_train)\n",
    "y_train_predict = etr.predict(X_train)\n",
    "y_predict = etr.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "#проверим для него лучшие параметры\n",
    "param_grid = {\n",
    "     #'n_estimators': [100],\n",
    "     'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "etr = ExtraTreeRegressor(random_state = RANDOM_SEED)\n",
    "etr_random = GridSearchCV(estimator=etr, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "etr_random.fit(X_train, y_train)\n",
    "print(etr_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train MAPE: 0.000\n",
      " Test MAPE: 0.081\n"
     ]
    }
   ],
   "source": [
    "etr = ExtraTreeRegressor(random_state = RANDOM_SEED, max_features = 'auto')\n",
    "etr.fit(X_train, y_train)\n",
    "y_train_predict = etr.predict(X_train)\n",
    "y_predict = etr.predict(X_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\\n            ...\\n            4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304],\\n           dtype='int64', length=3874)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-5df2452f3cd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m stacked_features_train, stacked_features_test = generate_metafeatures([\n\u001b[0m\u001b[0;32m     55\u001b[0m     RandomForestRegressor(random_state=RANDOM_SEED, n_estimators = 600, min_samples_split = 10, min_samples_leaf = 2, \n\u001b[0;32m     56\u001b[0m                             max_features = 'auto', max_depth = 100, bootstrap = True),\n",
      "\u001b[1;32m<ipython-input-151-5df2452f3cd6>\u001b[0m in \u001b[0;36mgenerate_metafeatures\u001b[1;34m(classifiers, X_train, X_test, y_train, cv)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0marg\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0mfolding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \"\"\"\n\u001b[1;32m---> 37\u001b[1;33m     features = [\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mcompute_meta_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-151-5df2452f3cd6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \"\"\"\n\u001b[0;32m     37\u001b[0m     features = [\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mcompute_meta_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     ]\n",
      "\u001b[1;32m<ipython-input-151-5df2452f3cd6>\u001b[0m in \u001b[0;36mcompute_meta_feature\u001b[1;34m(clf, X_train, X_test, y_train, cv)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mX_meta_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_fold_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_fold_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mX_fold_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fold_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_fold_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredict_fold_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0my_fold_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_fold_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m         self._validate_read_indexer(\n\u001b[0m\u001b[0;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\\n            ...\\n            4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304],\\n           dtype='int64', length=3874)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# проверим стэкинг с GradientBoostingRegressor c наилучшими парамерами, RandomForestRegressor \n",
    "\n",
    "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Computes meta-features using the classifier.\n",
    "    \n",
    "    :arg clf: scikit-learn classifier\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
    "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "        \n",
    "        folded_clf = clone(clf)\n",
    "        folded_clf.fit(X_fold_train, y_fold_train)\n",
    "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)[:, 1]\n",
    "    \n",
    "    meta_clf = clone(clf)\n",
    "    meta_clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_meta_test = meta_clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return X_meta_train, X_meta_test\n",
    "\n",
    "def generate_metafeatures(classifiers, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Generates metafeatures using a list of classifiers.\n",
    "    \n",
    "    :arg classifiers: list of scikit-learn classifiers\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
    "        for clf in tqdm(classifiers)\n",
    "    ]\n",
    "    \n",
    "    stacked_features_train = np.vstack([\n",
    "        features_train for features_train, features_test in features\n",
    "    ]).T\n",
    "\n",
    "    stacked_features_test = np.vstack([\n",
    "        features_test for features_train, features_test in features\n",
    "    ]).T\n",
    "    \n",
    "    return stacked_features_train, stacked_features_test\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_metafeatures([\n",
    "    RandomForestRegressor(random_state=RANDOM_SEED, n_estimators = 1200, min_samples_split = 2, min_samples_leaf = 1, \n",
    "                            max_features = 'sqrt', max_depth = 110, bootstrap = True),\n",
    "    GradientBoostingRegressor(random_state = RANDOM_SEED, learning_rate = 0.1, n_estimators = 750)\n",
    "], X_train, X_test, y_train, cv)\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(stacked_features_train, y_train)\n",
    "y_train_predict = clf.predict(stacked_features_train)\n",
    "y_predict = rf.predict(stacked_features_test)\n",
    "print(f\" Train MAPE: {mean_squared_error(y_train, y_train_predict):0.3f}\")\n",
    "print(f\" Test MAPE: {mean_squared_error(y_test, y_predict):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
